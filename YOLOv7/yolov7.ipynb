{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Ensure colab doesn't disconnect\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "metadata": {
        "id": "AmMgji6x5aVY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5c8e8100-064a-4de8-99ca-a83b3a02e6bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "function ClickConnect(){\n",
              "console.log(\"Working\");\n",
              "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}setInterval(ClickConnect,60000)\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps to run this code:\n",
        "\n",
        "1. Clone the Yolov7 official repository from the url: https://github.com/WongKinYiu/yolov7.git \n",
        "\n",
        "2. Add data in data folder with the folder structure as:\n",
        " - data/train/images for train images and data/train/labels for train labels\n",
        " - data/val/images for validation images and data/val/labels for validation labels\n",
        " - data/test/images for test images and data/test/labels for test labels\n",
        "\n",
        "3. Change the coco.yaml file as below:\n",
        "\n",
        "  train: data/train/images\n",
        "\n",
        "  val: data/val/images\n",
        "\n",
        "  test: data/test/images\n",
        "\n",
        "  nc: 2\n",
        "\n",
        "  names: ['vehicle', 'bike']\n",
        "\n",
        "4. In yolov7/cfg/training update yolov7.yaml and update nc: 2 since we have only 2 classes.\n",
        "\n",
        "5. Dowload and upload the pretrained Yolov7 weights from the github url: https://github.com/WongKinYiu/yolov7#performance \n",
        "\n",
        "6. Upload the complete folder on drive and start running below code cells.\n",
        "\n",
        "7. The code for this notebook is referenced and updated using this article: https://machinelearningprojects.net/train-yolov7-on-the-custom-dataset/ \n"
      ],
      "metadata": {
        "id": "fhD4y22O2s-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Drive and install requirements"
      ],
      "metadata": {
        "id": "IOSioD0u6NfV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPIATBodySRU",
        "outputId": "46b4ed23-fca6-45c2-caed-b72404f27dbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -r drive/MyDrive/yolov7/requirements.txt\n",
        "!pip install -r drive/MyDrive/yolov7/requirements_gpu.txt"
      ],
      "metadata": {
        "id": "w5_MUVd6yg1r"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/yolov7/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myB1T6QRyqC_",
        "outputId": "50cc30a0-476f-46f0-c2f6-eb5520aa3320"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolov7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Yolov7 model\n",
        "\n",
        "### Training with 10 epochs and 16 batch size, freezing first 50 layers since it is the backbone of Yolov7."
      ],
      "metadata": {
        "id": "pxbF3rKM6TCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --workers 1 --device 0 --batch-size 16 --epochs 10 --img 640 640 --hyp data/hyp.scratch.custom.yaml --name yolov7-custom --weights yolov7.pt --freeze 50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PguVrC5czoi6",
        "outputId": "eb3be14e-32d8-43c5-95ae-5eebe1230e7c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOR ðŸš€ v0.1-122-g3b41c2c torch 1.11.0+cu113 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Namespace(weights='yolov7.pt', cfg='', data='data/coco.yaml', hyp='data/hyp.scratch.custom.yaml', epochs=10, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=1, project='runs/train', entity=None, name='yolov7-custom', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[50], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/yolov7-custom4', total_batch_size=16)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-05-03 16:23:05.573499: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 16:23:07.577872: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     37695  models.yolo.Detect                      [2, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 407 layers, 37200095 parameters, 37200095 gradients, 105.1 GFLOPS\n",
            "\n",
            "Transferred 554/560 items from yolov7.pt\n",
            "freezing model.0.conv.weight\n",
            "freezing model.0.bn.weight\n",
            "freezing model.0.bn.bias\n",
            "freezing model.1.conv.weight\n",
            "freezing model.1.bn.weight\n",
            "freezing model.1.bn.bias\n",
            "freezing model.2.conv.weight\n",
            "freezing model.2.bn.weight\n",
            "freezing model.2.bn.bias\n",
            "freezing model.3.conv.weight\n",
            "freezing model.3.bn.weight\n",
            "freezing model.3.bn.bias\n",
            "freezing model.4.conv.weight\n",
            "freezing model.4.bn.weight\n",
            "freezing model.4.bn.bias\n",
            "freezing model.5.conv.weight\n",
            "freezing model.5.bn.weight\n",
            "freezing model.5.bn.bias\n",
            "freezing model.6.conv.weight\n",
            "freezing model.6.bn.weight\n",
            "freezing model.6.bn.bias\n",
            "freezing model.7.conv.weight\n",
            "freezing model.7.bn.weight\n",
            "freezing model.7.bn.bias\n",
            "freezing model.8.conv.weight\n",
            "freezing model.8.bn.weight\n",
            "freezing model.8.bn.bias\n",
            "freezing model.9.conv.weight\n",
            "freezing model.9.bn.weight\n",
            "freezing model.9.bn.bias\n",
            "freezing model.11.conv.weight\n",
            "freezing model.11.bn.weight\n",
            "freezing model.11.bn.bias\n",
            "freezing model.13.conv.weight\n",
            "freezing model.13.bn.weight\n",
            "freezing model.13.bn.bias\n",
            "freezing model.14.conv.weight\n",
            "freezing model.14.bn.weight\n",
            "freezing model.14.bn.bias\n",
            "freezing model.15.conv.weight\n",
            "freezing model.15.bn.weight\n",
            "freezing model.15.bn.bias\n",
            "freezing model.17.conv.weight\n",
            "freezing model.17.bn.weight\n",
            "freezing model.17.bn.bias\n",
            "freezing model.18.conv.weight\n",
            "freezing model.18.bn.weight\n",
            "freezing model.18.bn.bias\n",
            "freezing model.19.conv.weight\n",
            "freezing model.19.bn.weight\n",
            "freezing model.19.bn.bias\n",
            "freezing model.20.conv.weight\n",
            "freezing model.20.bn.weight\n",
            "freezing model.20.bn.bias\n",
            "freezing model.21.conv.weight\n",
            "freezing model.21.bn.weight\n",
            "freezing model.21.bn.bias\n",
            "freezing model.22.conv.weight\n",
            "freezing model.22.bn.weight\n",
            "freezing model.22.bn.bias\n",
            "freezing model.24.conv.weight\n",
            "freezing model.24.bn.weight\n",
            "freezing model.24.bn.bias\n",
            "freezing model.26.conv.weight\n",
            "freezing model.26.bn.weight\n",
            "freezing model.26.bn.bias\n",
            "freezing model.27.conv.weight\n",
            "freezing model.27.bn.weight\n",
            "freezing model.27.bn.bias\n",
            "freezing model.28.conv.weight\n",
            "freezing model.28.bn.weight\n",
            "freezing model.28.bn.bias\n",
            "freezing model.30.conv.weight\n",
            "freezing model.30.bn.weight\n",
            "freezing model.30.bn.bias\n",
            "freezing model.31.conv.weight\n",
            "freezing model.31.bn.weight\n",
            "freezing model.31.bn.bias\n",
            "freezing model.32.conv.weight\n",
            "freezing model.32.bn.weight\n",
            "freezing model.32.bn.bias\n",
            "freezing model.33.conv.weight\n",
            "freezing model.33.bn.weight\n",
            "freezing model.33.bn.bias\n",
            "freezing model.34.conv.weight\n",
            "freezing model.34.bn.weight\n",
            "freezing model.34.bn.bias\n",
            "freezing model.35.conv.weight\n",
            "freezing model.35.bn.weight\n",
            "freezing model.35.bn.bias\n",
            "freezing model.37.conv.weight\n",
            "freezing model.37.bn.weight\n",
            "freezing model.37.bn.bias\n",
            "freezing model.39.conv.weight\n",
            "freezing model.39.bn.weight\n",
            "freezing model.39.bn.bias\n",
            "freezing model.40.conv.weight\n",
            "freezing model.40.bn.weight\n",
            "freezing model.40.bn.bias\n",
            "freezing model.41.conv.weight\n",
            "freezing model.41.bn.weight\n",
            "freezing model.41.bn.bias\n",
            "freezing model.43.conv.weight\n",
            "freezing model.43.bn.weight\n",
            "freezing model.43.bn.bias\n",
            "freezing model.44.conv.weight\n",
            "freezing model.44.bn.weight\n",
            "freezing model.44.bn.bias\n",
            "freezing model.45.conv.weight\n",
            "freezing model.45.bn.weight\n",
            "freezing model.45.bn.bias\n",
            "freezing model.46.conv.weight\n",
            "freezing model.46.bn.weight\n",
            "freezing model.46.bn.bias\n",
            "freezing model.47.conv.weight\n",
            "freezing model.47.bn.weight\n",
            "freezing model.47.bn.bias\n",
            "freezing model.48.conv.weight\n",
            "freezing model.48.bn.weight\n",
            "freezing model.48.bn.bias\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 92 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'data/train/labels.cache' images and labels... 2596 found, 0 missing, 2 empty, 0 corrupted: 100% 2596/2596 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/val/labels.cache' images and labels... 300 found, 0 missing, 0 empty, 2 corrupted: 100% 300/300 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.53, Best Possible Recall (BPR) = 0.9938\n",
            "Image sizes 640 train, 640 test\n",
            "Using 1 dataloader workers\n",
            "Logging results to runs/train/yolov7-custom4\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/9     5.79G   0.06588    0.0218  0.008929   0.09661        67       640: 100% 163/163 [37:09<00:00, 13.68s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:12<00:00,  1.21s/it]\n",
            "                 all         298        2560        0.38       0.536        0.41       0.121\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/9     5.81G   0.05373   0.01813    0.0046   0.07646        44       640: 100% 163/163 [02:22<00:00,  1.15it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:05<00:00,  1.91it/s]\n",
            "                 all         298        2560       0.538       0.558       0.526       0.198\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/9     5.81G   0.04491    0.0173  0.003265   0.06547        53       640: 100% 163/163 [02:19<00:00,  1.17it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:05<00:00,  1.89it/s]\n",
            "                 all         298        2560       0.674        0.56       0.616       0.279\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       3/9     5.81G   0.04489   0.01763  0.003055   0.06558        95       640: 100% 163/163 [02:18<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:06<00:00,  1.66it/s]\n",
            "                 all         298        2560       0.698       0.634       0.671       0.307\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       4/9     5.81G   0.04048   0.01758  0.002787   0.06085        93       640: 100% 163/163 [02:19<00:00,  1.17it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:06<00:00,  1.59it/s]\n",
            "                 all         298        2560       0.732       0.584       0.649        0.31\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       5/9     5.81G   0.03877   0.01814  0.002412   0.05932        41       640: 100% 163/163 [02:19<00:00,  1.17it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:06<00:00,  1.64it/s]\n",
            "                 all         298        2560       0.734       0.623       0.676       0.315\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       6/9     5.81G   0.03537   0.01771  0.001999   0.05508        47       640: 100% 163/163 [02:23<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.31it/s]\n",
            "                 all         298        2560       0.738        0.61       0.674       0.325\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       7/9     5.81G   0.03334   0.01677  0.001659   0.05178        77       640: 100% 163/163 [02:22<00:00,  1.15it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.31it/s]\n",
            "                 all         298        2560       0.755       0.592       0.683       0.333\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       8/9     5.81G   0.03024   0.01683  0.001468   0.04854        44       640: 100% 163/163 [02:21<00:00,  1.16it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:06<00:00,  1.61it/s]\n",
            "                 all         298        2560       0.724       0.632       0.689       0.342\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       9/9     5.81G   0.02865   0.01677  0.001216   0.04663        61       640: 100% 163/163 [02:22<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:06<00:00,  1.48it/s]\n",
            "                 all         298        2560       0.754       0.661       0.714       0.356\n",
            "             vehicle         298        2192       0.857        0.76       0.863       0.546\n",
            "                bike         298         368       0.651       0.562       0.565       0.166\n",
            "10 epochs completed in 1.001 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/yolov7-custom4/weights/last.pt, 74.8MB\n",
            "Optimizer stripped from runs/train/yolov7-custom4/weights/best.pt, 74.8MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the code against test images stored in data/test/images"
      ],
      "metadata": {
        "id": "GDnsWA8K60uM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/yolov7-custom4/weights/best.pt --task test --data data/coco.yaml"
      ],
      "metadata": {
        "id": "CM8mVuzJ1jKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eb7eb13-158c-46da-ce0d-886d23ebfec8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights=['runs/train/yolov7-custom4/weights/best.pt'], data='data/coco.yaml', batch_size=32, img_size=640, conf_thres=0.001, iou_thres=0.65, task='test', device='', single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project='runs/test', name='exp', exist_ok=False, no_trace=False, v5_metric=False)\n",
            "YOLOR ðŸš€ v0.1-122-g3b41c2c torch 1.11.0+cu113 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 306 layers, 36485311 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'data/test/labels.cache' images and labels... 108 found, 0 missing, 0 empty, 0 corrupted: 100% 108/108 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.11it/s]\n",
            "                 all         108         232       0.526       0.838       0.636       0.342\n",
            "             vehicle         108         227       0.653       0.877       0.883       0.546\n",
            "                bike         108           5       0.398         0.8       0.389       0.138\n",
            "Speed: 10.3/3.0/13.3 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp9/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training for next 10 iterations with the updated weights"
      ],
      "metadata": {
        "id": "ZpUEDVW967YQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --workers 1 --device 0 --batch-size 16 --epochs 10 --img 640 640 --hyp data/hyp.scratch.custom.yaml --name yolov7-custom --weights runs/train/yolov7-custom4/weights/best.pt --freeze 50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfbfQitcgjcp",
        "outputId": "ecfd7097-5c48-480c-bc27-14dcf2b4c0c6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOR ðŸš€ v0.1-122-g3b41c2c torch 1.11.0+cu113 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Namespace(weights='runs/train/yolov7-custom4/weights/best.pt', cfg='', data='data/coco.yaml', hyp='data/hyp.scratch.custom.yaml', epochs=10, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=1, project='runs/train', entity=None, name='yolov7-custom', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[50], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/yolov7-custom5', total_batch_size=16)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-05-03 21:29:17.266898: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 21:29:19.420903: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     37695  models.yolo.Detect                      [2, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 407 layers, 37200095 parameters, 37200095 gradients, 105.1 GFLOPS\n",
            "\n",
            "Transferred 560/560 items from runs/train/yolov7-custom4/weights/best.pt\n",
            "freezing model.0.conv.weight\n",
            "freezing model.0.bn.weight\n",
            "freezing model.0.bn.bias\n",
            "freezing model.1.conv.weight\n",
            "freezing model.1.bn.weight\n",
            "freezing model.1.bn.bias\n",
            "freezing model.2.conv.weight\n",
            "freezing model.2.bn.weight\n",
            "freezing model.2.bn.bias\n",
            "freezing model.3.conv.weight\n",
            "freezing model.3.bn.weight\n",
            "freezing model.3.bn.bias\n",
            "freezing model.4.conv.weight\n",
            "freezing model.4.bn.weight\n",
            "freezing model.4.bn.bias\n",
            "freezing model.5.conv.weight\n",
            "freezing model.5.bn.weight\n",
            "freezing model.5.bn.bias\n",
            "freezing model.6.conv.weight\n",
            "freezing model.6.bn.weight\n",
            "freezing model.6.bn.bias\n",
            "freezing model.7.conv.weight\n",
            "freezing model.7.bn.weight\n",
            "freezing model.7.bn.bias\n",
            "freezing model.8.conv.weight\n",
            "freezing model.8.bn.weight\n",
            "freezing model.8.bn.bias\n",
            "freezing model.9.conv.weight\n",
            "freezing model.9.bn.weight\n",
            "freezing model.9.bn.bias\n",
            "freezing model.11.conv.weight\n",
            "freezing model.11.bn.weight\n",
            "freezing model.11.bn.bias\n",
            "freezing model.13.conv.weight\n",
            "freezing model.13.bn.weight\n",
            "freezing model.13.bn.bias\n",
            "freezing model.14.conv.weight\n",
            "freezing model.14.bn.weight\n",
            "freezing model.14.bn.bias\n",
            "freezing model.15.conv.weight\n",
            "freezing model.15.bn.weight\n",
            "freezing model.15.bn.bias\n",
            "freezing model.17.conv.weight\n",
            "freezing model.17.bn.weight\n",
            "freezing model.17.bn.bias\n",
            "freezing model.18.conv.weight\n",
            "freezing model.18.bn.weight\n",
            "freezing model.18.bn.bias\n",
            "freezing model.19.conv.weight\n",
            "freezing model.19.bn.weight\n",
            "freezing model.19.bn.bias\n",
            "freezing model.20.conv.weight\n",
            "freezing model.20.bn.weight\n",
            "freezing model.20.bn.bias\n",
            "freezing model.21.conv.weight\n",
            "freezing model.21.bn.weight\n",
            "freezing model.21.bn.bias\n",
            "freezing model.22.conv.weight\n",
            "freezing model.22.bn.weight\n",
            "freezing model.22.bn.bias\n",
            "freezing model.24.conv.weight\n",
            "freezing model.24.bn.weight\n",
            "freezing model.24.bn.bias\n",
            "freezing model.26.conv.weight\n",
            "freezing model.26.bn.weight\n",
            "freezing model.26.bn.bias\n",
            "freezing model.27.conv.weight\n",
            "freezing model.27.bn.weight\n",
            "freezing model.27.bn.bias\n",
            "freezing model.28.conv.weight\n",
            "freezing model.28.bn.weight\n",
            "freezing model.28.bn.bias\n",
            "freezing model.30.conv.weight\n",
            "freezing model.30.bn.weight\n",
            "freezing model.30.bn.bias\n",
            "freezing model.31.conv.weight\n",
            "freezing model.31.bn.weight\n",
            "freezing model.31.bn.bias\n",
            "freezing model.32.conv.weight\n",
            "freezing model.32.bn.weight\n",
            "freezing model.32.bn.bias\n",
            "freezing model.33.conv.weight\n",
            "freezing model.33.bn.weight\n",
            "freezing model.33.bn.bias\n",
            "freezing model.34.conv.weight\n",
            "freezing model.34.bn.weight\n",
            "freezing model.34.bn.bias\n",
            "freezing model.35.conv.weight\n",
            "freezing model.35.bn.weight\n",
            "freezing model.35.bn.bias\n",
            "freezing model.37.conv.weight\n",
            "freezing model.37.bn.weight\n",
            "freezing model.37.bn.bias\n",
            "freezing model.39.conv.weight\n",
            "freezing model.39.bn.weight\n",
            "freezing model.39.bn.bias\n",
            "freezing model.40.conv.weight\n",
            "freezing model.40.bn.weight\n",
            "freezing model.40.bn.bias\n",
            "freezing model.41.conv.weight\n",
            "freezing model.41.bn.weight\n",
            "freezing model.41.bn.bias\n",
            "freezing model.43.conv.weight\n",
            "freezing model.43.bn.weight\n",
            "freezing model.43.bn.bias\n",
            "freezing model.44.conv.weight\n",
            "freezing model.44.bn.weight\n",
            "freezing model.44.bn.bias\n",
            "freezing model.45.conv.weight\n",
            "freezing model.45.bn.weight\n",
            "freezing model.45.bn.bias\n",
            "freezing model.46.conv.weight\n",
            "freezing model.46.bn.weight\n",
            "freezing model.46.bn.bias\n",
            "freezing model.47.conv.weight\n",
            "freezing model.47.bn.weight\n",
            "freezing model.47.bn.bias\n",
            "freezing model.48.conv.weight\n",
            "freezing model.48.bn.weight\n",
            "freezing model.48.bn.bias\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 92 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'data/train/labels.cache' images and labels... 2596 found, 0 missing, 2 empty, 0 corrupted: 100% 2596/2596 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/val/labels.cache' images and labels... 300 found, 0 missing, 0 empty, 2 corrupted: 100% 300/300 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.53, Best Possible Recall (BPR) = 0.9938\n",
            "Image sizes 640 train, 640 test\n",
            "Using 1 dataloader workers\n",
            "Logging results to runs/train/yolov7-custom5\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/9     5.79G    0.0279   0.01647  0.001087   0.04545        67       640: 100% 163/163 [12:03<00:00,  4.44s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:13<00:00,  1.32s/it]\n",
            "                 all         298        2560       0.795       0.639       0.727       0.382\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/9     5.81G   0.02896   0.01651  0.001092   0.04656        44       640: 100% 163/163 [02:16<00:00,  1.20it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.26it/s]\n",
            "                 all         298        2560       0.738       0.677       0.721       0.367\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/9     5.81G   0.02924   0.01569  0.001102   0.04604        53       640: 100% 163/163 [02:11<00:00,  1.24it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:05<00:00,  1.76it/s]\n",
            "                 all         298        2560         0.8       0.641       0.744       0.393\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       3/9     5.81G   0.03219   0.01611   0.00129   0.04959        95       640: 100% 163/163 [02:11<00:00,  1.24it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:05<00:00,  1.72it/s]\n",
            "                 all         298        2560       0.738        0.64       0.699       0.358\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       4/9     5.81G   0.03108   0.01565   0.00123   0.04795        93       640: 100% 163/163 [02:10<00:00,  1.25it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.24it/s]\n",
            "                 all         298        2560       0.715        0.67       0.687       0.354\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       5/9     5.81G   0.03185   0.01602  0.001244   0.04912        41       640: 100% 163/163 [02:12<00:00,  1.23it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.35it/s]\n",
            "                 all         298        2560       0.746       0.677       0.728       0.353\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       6/9     5.81G   0.02951   0.01563   0.00115   0.04629        47       640: 100% 163/163 [02:11<00:00,  1.24it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:05<00:00,  1.97it/s]\n",
            "                 all         298        2560       0.778       0.639       0.693       0.366\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       7/9     5.81G   0.02911     0.015  0.001014   0.04513        77       640: 100% 163/163 [02:10<00:00,  1.25it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:05<00:00,  1.68it/s]\n",
            "                 all         298        2560       0.796       0.627       0.716       0.364\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       8/9     5.81G   0.02689   0.01535  0.000967   0.04321        44       640: 100% 163/163 [02:11<00:00,  1.24it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:05<00:00,  1.99it/s]\n",
            "                 all         298        2560       0.802       0.639       0.727       0.381\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       9/9     5.81G   0.02627   0.01539 0.0008373    0.0425        61       640: 100% 163/163 [02:14<00:00,  1.21it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:08<00:00,  1.19it/s]\n",
            "                 all         298        2560        0.79       0.646       0.717       0.369\n",
            "             vehicle         298        2192       0.869       0.746        0.86       0.553\n",
            "                bike         298         368       0.711       0.546       0.574       0.185\n",
            "10 epochs completed in 0.557 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/yolov7-custom5/weights/last.pt, 74.8MB\n",
            "Optimizer stripped from runs/train/yolov7-custom5/weights/best.pt, 74.8MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the code with best weights achieved against test images stored in data/test/images"
      ],
      "metadata": {
        "id": "_DZK4ezO7OL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/yolov7-custom5/weights/best.pt --task test --data data/coco.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RZLpmtX7xr2",
        "outputId": "0b2cfaca-c354-4d61-8a15-0e4ec01cf6d2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights=['runs/train/yolov7-custom5/weights/best.pt'], data='data/coco.yaml', batch_size=32, img_size=640, conf_thres=0.001, iou_thres=0.65, task='test', device='', single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project='runs/test', name='exp', exist_ok=False, no_trace=False, v5_metric=False)\n",
            "YOLOR ðŸš€ v0.1-122-g3b41c2c torch 1.11.0+cu113 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 306 layers, 36485311 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'data/test/labels.cache' images and labels... 108 found, 0 missing, 0 empty, 0 corrupted: 100% 108/108 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.28it/s]\n",
            "                 all         108         232       0.573       0.625       0.567       0.291\n",
            "             vehicle         108         227       0.814        0.85       0.883       0.543\n",
            "                bike         108           5       0.333         0.4       0.252      0.0387\n",
            "Speed: 11.2/3.0/14.2 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp10/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --workers 1 --device 0 --batch-size 16 --epochs 10 --img 640 640 --hyp data/hyp.scratch.custom.yaml --name yolov7-custom --weights yolov7.pt --freeze 50 --multi-scale"
      ],
      "metadata": {
        "id": "YIB7oeuqGer6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67892ecd-793e-42ed-94cf-9c39910cf675"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOR ðŸš€ v0.1-122-g3b41c2c torch 1.11.0+cu113 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Namespace(weights='yolov7.pt', cfg='', data='data/coco.yaml', hyp='data/hyp.scratch.custom.yaml', epochs=10, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=True, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=1, project='runs/train', entity=None, name='yolov7-custom', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[50], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/yolov7-custom6', total_batch_size=16)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-05-03 22:07:12.702996: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 22:07:14.882942: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     37695  models.yolo.Detect                      [2, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 407 layers, 37200095 parameters, 37200095 gradients, 105.1 GFLOPS\n",
            "\n",
            "Transferred 554/560 items from yolov7.pt\n",
            "freezing model.0.conv.weight\n",
            "freezing model.0.bn.weight\n",
            "freezing model.0.bn.bias\n",
            "freezing model.1.conv.weight\n",
            "freezing model.1.bn.weight\n",
            "freezing model.1.bn.bias\n",
            "freezing model.2.conv.weight\n",
            "freezing model.2.bn.weight\n",
            "freezing model.2.bn.bias\n",
            "freezing model.3.conv.weight\n",
            "freezing model.3.bn.weight\n",
            "freezing model.3.bn.bias\n",
            "freezing model.4.conv.weight\n",
            "freezing model.4.bn.weight\n",
            "freezing model.4.bn.bias\n",
            "freezing model.5.conv.weight\n",
            "freezing model.5.bn.weight\n",
            "freezing model.5.bn.bias\n",
            "freezing model.6.conv.weight\n",
            "freezing model.6.bn.weight\n",
            "freezing model.6.bn.bias\n",
            "freezing model.7.conv.weight\n",
            "freezing model.7.bn.weight\n",
            "freezing model.7.bn.bias\n",
            "freezing model.8.conv.weight\n",
            "freezing model.8.bn.weight\n",
            "freezing model.8.bn.bias\n",
            "freezing model.9.conv.weight\n",
            "freezing model.9.bn.weight\n",
            "freezing model.9.bn.bias\n",
            "freezing model.11.conv.weight\n",
            "freezing model.11.bn.weight\n",
            "freezing model.11.bn.bias\n",
            "freezing model.13.conv.weight\n",
            "freezing model.13.bn.weight\n",
            "freezing model.13.bn.bias\n",
            "freezing model.14.conv.weight\n",
            "freezing model.14.bn.weight\n",
            "freezing model.14.bn.bias\n",
            "freezing model.15.conv.weight\n",
            "freezing model.15.bn.weight\n",
            "freezing model.15.bn.bias\n",
            "freezing model.17.conv.weight\n",
            "freezing model.17.bn.weight\n",
            "freezing model.17.bn.bias\n",
            "freezing model.18.conv.weight\n",
            "freezing model.18.bn.weight\n",
            "freezing model.18.bn.bias\n",
            "freezing model.19.conv.weight\n",
            "freezing model.19.bn.weight\n",
            "freezing model.19.bn.bias\n",
            "freezing model.20.conv.weight\n",
            "freezing model.20.bn.weight\n",
            "freezing model.20.bn.bias\n",
            "freezing model.21.conv.weight\n",
            "freezing model.21.bn.weight\n",
            "freezing model.21.bn.bias\n",
            "freezing model.22.conv.weight\n",
            "freezing model.22.bn.weight\n",
            "freezing model.22.bn.bias\n",
            "freezing model.24.conv.weight\n",
            "freezing model.24.bn.weight\n",
            "freezing model.24.bn.bias\n",
            "freezing model.26.conv.weight\n",
            "freezing model.26.bn.weight\n",
            "freezing model.26.bn.bias\n",
            "freezing model.27.conv.weight\n",
            "freezing model.27.bn.weight\n",
            "freezing model.27.bn.bias\n",
            "freezing model.28.conv.weight\n",
            "freezing model.28.bn.weight\n",
            "freezing model.28.bn.bias\n",
            "freezing model.30.conv.weight\n",
            "freezing model.30.bn.weight\n",
            "freezing model.30.bn.bias\n",
            "freezing model.31.conv.weight\n",
            "freezing model.31.bn.weight\n",
            "freezing model.31.bn.bias\n",
            "freezing model.32.conv.weight\n",
            "freezing model.32.bn.weight\n",
            "freezing model.32.bn.bias\n",
            "freezing model.33.conv.weight\n",
            "freezing model.33.bn.weight\n",
            "freezing model.33.bn.bias\n",
            "freezing model.34.conv.weight\n",
            "freezing model.34.bn.weight\n",
            "freezing model.34.bn.bias\n",
            "freezing model.35.conv.weight\n",
            "freezing model.35.bn.weight\n",
            "freezing model.35.bn.bias\n",
            "freezing model.37.conv.weight\n",
            "freezing model.37.bn.weight\n",
            "freezing model.37.bn.bias\n",
            "freezing model.39.conv.weight\n",
            "freezing model.39.bn.weight\n",
            "freezing model.39.bn.bias\n",
            "freezing model.40.conv.weight\n",
            "freezing model.40.bn.weight\n",
            "freezing model.40.bn.bias\n",
            "freezing model.41.conv.weight\n",
            "freezing model.41.bn.weight\n",
            "freezing model.41.bn.bias\n",
            "freezing model.43.conv.weight\n",
            "freezing model.43.bn.weight\n",
            "freezing model.43.bn.bias\n",
            "freezing model.44.conv.weight\n",
            "freezing model.44.bn.weight\n",
            "freezing model.44.bn.bias\n",
            "freezing model.45.conv.weight\n",
            "freezing model.45.bn.weight\n",
            "freezing model.45.bn.bias\n",
            "freezing model.46.conv.weight\n",
            "freezing model.46.bn.weight\n",
            "freezing model.46.bn.bias\n",
            "freezing model.47.conv.weight\n",
            "freezing model.47.bn.weight\n",
            "freezing model.47.bn.bias\n",
            "freezing model.48.conv.weight\n",
            "freezing model.48.bn.weight\n",
            "freezing model.48.bn.bias\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 92 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'data/train/labels.cache' images and labels... 2596 found, 0 missing, 2 empty, 0 corrupted: 100% 2596/2596 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/val/labels.cache' images and labels... 300 found, 0 missing, 0 empty, 2 corrupted: 100% 300/300 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.53, Best Possible Recall (BPR) = 0.9938\n",
            "Image sizes 640 train, 640 test\n",
            "Using 1 dataloader workers\n",
            "Logging results to runs/train/yolov7-custom6\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "  0% 0/163 [00:00<?, ?it/s]/content/drive/MyDrive/yolov7/train.py:353: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
            "  sz = random.randrange(imgsz * 0.5, imgsz * 1.5 + gs) // gs * gs  # size\n",
            "       0/9     1.91G    0.0671   0.02374  0.009111   0.09995        67       608: 100% 163/163 [06:23<00:00,  2.35s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:12<00:00,  1.29s/it]\n",
            "                 all         298        2560       0.351       0.469       0.316      0.0792\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/9     2.85G    0.0534   0.02101  0.004659   0.07906        44       864: 100% 163/163 [02:25<00:00,  1.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.34it/s]\n",
            "                 all         298        2560       0.607       0.526       0.537       0.164\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/9     4.22G   0.04606   0.02116  0.003496   0.07072        53       352: 100% 163/163 [02:17<00:00,  1.19it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.39it/s]\n",
            "                 all         298        2560       0.734       0.579       0.659       0.299\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       3/9     4.26G   0.04535    0.0195  0.003304   0.06815        95       416: 100% 163/163 [02:18<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.33it/s]\n",
            "                 all         298        2560       0.679       0.623       0.646       0.285\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       4/9     4.27G    0.0412    0.0197  0.002811   0.06371        93       480: 100% 163/163 [02:17<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.09it/s]\n",
            "                 all         298        2560       0.707       0.587       0.626       0.289\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       5/9     1.87G   0.03989   0.02369  0.002485   0.06607        41       832: 100% 163/163 [02:18<00:00,  1.17it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.27it/s]\n",
            "                 all         298        2560       0.736       0.574       0.653       0.306\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       6/9     1.87G   0.03553   0.01961  0.002078   0.05722        47       736: 100% 163/163 [02:25<00:00,  1.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:05<00:00,  1.89it/s]\n",
            "                 all         298        2560       0.715       0.603        0.66       0.323\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       7/9     11.9G   0.03429   0.01981  0.001788   0.05589        77       736: 100% 163/163 [02:15<00:00,  1.21it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:05<00:00,  1.82it/s]\n",
            "                 all         298        2560       0.769       0.593       0.667       0.321\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       8/9     1.88G   0.03107   0.01987  0.001609   0.05254        44       640: 100% 163/163 [02:21<00:00,  1.15it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.33it/s]\n",
            "                 all         298        2560        0.74       0.592       0.652       0.316\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       9/9      4.3G   0.02978   0.02055  0.001401   0.05174        61       512: 100% 163/163 [02:18<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:06<00:00,  1.47it/s]\n",
            "                 all         298        2560       0.771       0.601       0.683       0.345\n",
            "             vehicle         298        2192       0.884       0.731       0.858       0.547\n",
            "                bike         298         368       0.658       0.471       0.508       0.143\n",
            "10 epochs completed in 0.482 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/yolov7-custom6/weights/last.pt, 74.8MB\n",
            "Optimizer stripped from runs/train/yolov7-custom6/weights/best.pt, 74.8MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/yolov7-custom6/weights/best.pt --task test --data data/coco.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR1ElORAts-y",
        "outputId": "40f0e664-e27b-422c-e1fa-1b55cd376ab9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights=['runs/train/yolov7-custom7/weights/best.pt'], data='data/coco.yaml', batch_size=32, img_size=640, conf_thres=0.001, iou_thres=0.65, task='test', device='', single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project='runs/test', name='exp', exist_ok=False, no_trace=False, v5_metric=False)\n",
            "YOLOR ðŸš€ v0.1-122-g3b41c2c torch 1.11.0+cu113 CPU\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 306 layers, 36485311 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'data/test/labels.cache' images and labels... 108 found, 0 missing, 0 empty, 0 corrupted: 100% 108/108 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [03:06<00:00, 46.63s/it]\n",
            "                 all         108         232       0.639       0.733       0.595       0.287\n",
            "             vehicle         108         227       0.779       0.868       0.885       0.522\n",
            "                bike         108           5       0.499       0.599       0.305      0.0516\n",
            "Speed: 1710.0/0.5/1710.5 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp17/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --workers 1 --device 0 --batch-size 16 --epochs 20 --img 640 640 --hyp data/hyp.scratch.custom.yaml --name yolov7-custom --weights yolov7.pt --freeze 50 --multi-scale"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwrUPVcEp6lC",
        "outputId": "519d63de-13e3-4970-a436-4e1e9feafb50"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOR ðŸš€ v0.1-122-g3b41c2c torch 1.11.0+cu113 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Namespace(weights='yolov7.pt', cfg='', data='data/coco.yaml', hyp='data/hyp.scratch.custom.yaml', epochs=20, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=True, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=1, project='runs/train', entity=None, name='yolov7-custom', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[50], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/yolov7-custom7', total_batch_size=16)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-05-03 22:59:44.434212: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 22:59:46.516745: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     37695  models.yolo.Detect                      [2, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 407 layers, 37200095 parameters, 37200095 gradients, 105.1 GFLOPS\n",
            "\n",
            "Transferred 554/560 items from yolov7.pt\n",
            "freezing model.0.conv.weight\n",
            "freezing model.0.bn.weight\n",
            "freezing model.0.bn.bias\n",
            "freezing model.1.conv.weight\n",
            "freezing model.1.bn.weight\n",
            "freezing model.1.bn.bias\n",
            "freezing model.2.conv.weight\n",
            "freezing model.2.bn.weight\n",
            "freezing model.2.bn.bias\n",
            "freezing model.3.conv.weight\n",
            "freezing model.3.bn.weight\n",
            "freezing model.3.bn.bias\n",
            "freezing model.4.conv.weight\n",
            "freezing model.4.bn.weight\n",
            "freezing model.4.bn.bias\n",
            "freezing model.5.conv.weight\n",
            "freezing model.5.bn.weight\n",
            "freezing model.5.bn.bias\n",
            "freezing model.6.conv.weight\n",
            "freezing model.6.bn.weight\n",
            "freezing model.6.bn.bias\n",
            "freezing model.7.conv.weight\n",
            "freezing model.7.bn.weight\n",
            "freezing model.7.bn.bias\n",
            "freezing model.8.conv.weight\n",
            "freezing model.8.bn.weight\n",
            "freezing model.8.bn.bias\n",
            "freezing model.9.conv.weight\n",
            "freezing model.9.bn.weight\n",
            "freezing model.9.bn.bias\n",
            "freezing model.11.conv.weight\n",
            "freezing model.11.bn.weight\n",
            "freezing model.11.bn.bias\n",
            "freezing model.13.conv.weight\n",
            "freezing model.13.bn.weight\n",
            "freezing model.13.bn.bias\n",
            "freezing model.14.conv.weight\n",
            "freezing model.14.bn.weight\n",
            "freezing model.14.bn.bias\n",
            "freezing model.15.conv.weight\n",
            "freezing model.15.bn.weight\n",
            "freezing model.15.bn.bias\n",
            "freezing model.17.conv.weight\n",
            "freezing model.17.bn.weight\n",
            "freezing model.17.bn.bias\n",
            "freezing model.18.conv.weight\n",
            "freezing model.18.bn.weight\n",
            "freezing model.18.bn.bias\n",
            "freezing model.19.conv.weight\n",
            "freezing model.19.bn.weight\n",
            "freezing model.19.bn.bias\n",
            "freezing model.20.conv.weight\n",
            "freezing model.20.bn.weight\n",
            "freezing model.20.bn.bias\n",
            "freezing model.21.conv.weight\n",
            "freezing model.21.bn.weight\n",
            "freezing model.21.bn.bias\n",
            "freezing model.22.conv.weight\n",
            "freezing model.22.bn.weight\n",
            "freezing model.22.bn.bias\n",
            "freezing model.24.conv.weight\n",
            "freezing model.24.bn.weight\n",
            "freezing model.24.bn.bias\n",
            "freezing model.26.conv.weight\n",
            "freezing model.26.bn.weight\n",
            "freezing model.26.bn.bias\n",
            "freezing model.27.conv.weight\n",
            "freezing model.27.bn.weight\n",
            "freezing model.27.bn.bias\n",
            "freezing model.28.conv.weight\n",
            "freezing model.28.bn.weight\n",
            "freezing model.28.bn.bias\n",
            "freezing model.30.conv.weight\n",
            "freezing model.30.bn.weight\n",
            "freezing model.30.bn.bias\n",
            "freezing model.31.conv.weight\n",
            "freezing model.31.bn.weight\n",
            "freezing model.31.bn.bias\n",
            "freezing model.32.conv.weight\n",
            "freezing model.32.bn.weight\n",
            "freezing model.32.bn.bias\n",
            "freezing model.33.conv.weight\n",
            "freezing model.33.bn.weight\n",
            "freezing model.33.bn.bias\n",
            "freezing model.34.conv.weight\n",
            "freezing model.34.bn.weight\n",
            "freezing model.34.bn.bias\n",
            "freezing model.35.conv.weight\n",
            "freezing model.35.bn.weight\n",
            "freezing model.35.bn.bias\n",
            "freezing model.37.conv.weight\n",
            "freezing model.37.bn.weight\n",
            "freezing model.37.bn.bias\n",
            "freezing model.39.conv.weight\n",
            "freezing model.39.bn.weight\n",
            "freezing model.39.bn.bias\n",
            "freezing model.40.conv.weight\n",
            "freezing model.40.bn.weight\n",
            "freezing model.40.bn.bias\n",
            "freezing model.41.conv.weight\n",
            "freezing model.41.bn.weight\n",
            "freezing model.41.bn.bias\n",
            "freezing model.43.conv.weight\n",
            "freezing model.43.bn.weight\n",
            "freezing model.43.bn.bias\n",
            "freezing model.44.conv.weight\n",
            "freezing model.44.bn.weight\n",
            "freezing model.44.bn.bias\n",
            "freezing model.45.conv.weight\n",
            "freezing model.45.bn.weight\n",
            "freezing model.45.bn.bias\n",
            "freezing model.46.conv.weight\n",
            "freezing model.46.bn.weight\n",
            "freezing model.46.bn.bias\n",
            "freezing model.47.conv.weight\n",
            "freezing model.47.bn.weight\n",
            "freezing model.47.bn.bias\n",
            "freezing model.48.conv.weight\n",
            "freezing model.48.bn.weight\n",
            "freezing model.48.bn.bias\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 92 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'data/train/labels.cache' images and labels... 2596 found, 0 missing, 2 empty, 0 corrupted: 100% 2596/2596 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/val/labels.cache' images and labels... 300 found, 0 missing, 0 empty, 2 corrupted: 100% 300/300 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.53, Best Possible Recall (BPR) = 0.9938\n",
            "Image sizes 640 train, 640 test\n",
            "Using 1 dataloader workers\n",
            "Logging results to runs/train/yolov7-custom7\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "  0% 0/163 [00:00<?, ?it/s]/content/drive/MyDrive/yolov7/train.py:353: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
            "  sz = random.randrange(imgsz * 0.5, imgsz * 1.5 + gs) // gs * gs  # size\n",
            "      0/19     1.91G   0.06658   0.02376  0.009097   0.09943        67       608: 100% 163/163 [06:14<00:00,  2.29s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:12<00:00,  1.29s/it]\n",
            "                 all         298        2560       0.309       0.599       0.436       0.152\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/19     2.85G   0.05461   0.02057  0.004877   0.08006        44       864: 100% 163/163 [02:31<00:00,  1.08it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.20it/s]\n",
            "                 all         298        2560       0.506       0.442       0.428       0.128\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/19     4.22G    0.0466   0.02105  0.003581   0.07123        53       352: 100% 163/163 [02:21<00:00,  1.16it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:05<00:00,  1.78it/s]\n",
            "                 all         298        2560       0.738       0.594       0.677       0.321\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/19     4.26G   0.04573   0.01983  0.003241    0.0688        95       416: 100% 163/163 [02:21<00:00,  1.15it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.39it/s]\n",
            "                 all         298        2560       0.649       0.605       0.619       0.258\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/19     4.27G   0.04209   0.01947  0.002773   0.06434        93       480: 100% 163/163 [02:23<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.22it/s]\n",
            "                 all         298        2560       0.729       0.544       0.612       0.279\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/19     1.87G   0.04226   0.02354  0.002608   0.06841        41       832: 100% 163/163 [02:26<00:00,  1.11it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.34it/s]\n",
            "                 all         298        2560       0.555       0.547       0.525       0.232\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/19     1.86G   0.03751    0.0195  0.002259   0.05926        47       736: 100% 163/163 [02:32<00:00,  1.07it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.35it/s]\n",
            "                 all         298        2560       0.718       0.602       0.666       0.312\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/19     11.9G   0.03602   0.01985  0.001915   0.05779        77       736: 100% 163/163 [02:18<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.30it/s]\n",
            "                 all         298        2560       0.753       0.596       0.672       0.325\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/19     1.88G   0.03366   0.01977   0.00173   0.05516        44       640: 100% 163/163 [02:25<00:00,  1.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.37it/s]\n",
            "                 all         298        2560       0.711        0.63       0.678       0.322\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/19      4.3G   0.03238   0.02072   0.00153   0.05462        61       512: 100% 163/163 [02:20<00:00,  1.16it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.41it/s]\n",
            "                 all         298        2560       0.728         0.6       0.664       0.319\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/19     1.89G   0.03164   0.01954  0.001443   0.05262        33       800: 100% 163/163 [02:25<00:00,  1.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:05<00:00,  1.96it/s]\n",
            "                 all         298        2560       0.748       0.649       0.708       0.354\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/19     10.2G   0.03046   0.01884  0.001268   0.05057        61       800: 100% 163/163 [02:12<00:00,  1.23it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:05<00:00,  1.73it/s]\n",
            "                 all         298        2560       0.722       0.641       0.692        0.34\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/19     10.2G   0.03001   0.01933  0.001184   0.05053        76       736: 100% 163/163 [02:13<00:00,  1.22it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:05<00:00,  1.95it/s]\n",
            "                 all         298        2560       0.729        0.65       0.696       0.341\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/19     10.2G   0.02896   0.02035  0.001135   0.05044        36       512: 100% 163/163 [02:11<00:00,  1.24it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.32it/s]\n",
            "                 all         298        2560       0.737       0.652       0.709       0.368\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/19     10.2G   0.02839   0.01838  0.001078   0.04785        53       512: 100% 163/163 [02:15<00:00,  1.20it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.27it/s]\n",
            "                 all         298        2560       0.747       0.682       0.738       0.385\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/19     4.29G   0.02785   0.01795 0.0009351   0.04674        43       320: 100% 163/163 [02:17<00:00,  1.19it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.47it/s]\n",
            "                 all         298        2560       0.779        0.65       0.733       0.384\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/19     1.85G   0.02708   0.01791 0.0008776   0.04587        16       544: 100% 163/163 [02:22<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.03it/s]\n",
            "                 all         298        2560       0.744       0.667       0.723       0.376\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/19     2.85G   0.02659   0.01888 0.0008728   0.04634        33       928: 100% 163/163 [02:22<00:00,  1.15it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.29it/s]\n",
            "                 all         298        2560       0.759       0.679        0.73       0.378\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/19     10.1G   0.02684   0.01745 0.0008298   0.04512        30       352: 100% 163/163 [02:14<00:00,  1.21it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.00it/s]\n",
            "                 all         298        2560       0.747       0.696       0.748       0.396\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/19     2.43G   0.02681   0.01783 0.0007849   0.04542        74       960: 100% 163/163 [02:23<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:06<00:00,  1.61it/s]\n",
            "                 all         298        2560       0.763       0.652       0.719       0.383\n",
            "             vehicle         298        2192       0.858       0.772       0.862       0.565\n",
            "                bike         298         368       0.669       0.533       0.576         0.2\n",
            "20 epochs completed in 0.891 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/yolov7-custom7/weights/last.pt, 74.8MB\n",
            "Optimizer stripped from runs/train/yolov7-custom7/weights/best.pt, 74.8MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/yolov7-custom6/weights/best.pt --task test --data data/coco.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I58cdL-mP9Gj",
        "outputId": "72dd4c0c-5bd0-4cb7-e209-5661b89226ef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights=['runs/train/yolov7-custom6/weights/best.pt'], data='data/coco.yaml', batch_size=32, img_size=640, conf_thres=0.001, iou_thres=0.65, task='test', device='', single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project='runs/test', name='exp', exist_ok=False, no_trace=False, v5_metric=False)\n",
            "YOLOR ðŸš€ v0.1-122-g3b41c2c torch 1.11.0+cu113 CPU\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 306 layers, 36485311 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'data/test/labels.cache' images and labels... 108 found, 0 missing, 0 empty, 0 corrupted: 100% 108/108 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [03:04<00:00, 46.21s/it]\n",
            "                 all         108         232       0.735       0.814       0.732       0.348\n",
            "             vehicle         108         227       0.803       0.828       0.862       0.521\n",
            "                bike         108           5       0.667         0.8       0.601       0.174\n",
            "Speed: 1692.5/0.6/1693.1 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp16/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trying the best weights on a video"
      ],
      "metadata": {
        "id": "jJmrTqqBt3sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/yolov7-custom7/weights/best.pt --conf 0.25 --img-size 1280 --source traffic-27260.mp4 --name test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANEeV3s6xHUn",
        "outputId": "4d405d10-b771-4bf9-c2db-927caa5d26c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights=['runs/train/yolov7-b16e30/weights/best.pt'], source='traffic-27260.mp4', img_size=1280, conf_thres=0.5, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='test', exist_ok=False, no_trace=False)\n",
            "YOLOR ðŸš€ v0.1-122-g3b41c2c torch 1.11.0+cu113 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 306 layers, 36485311 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "video 1/1 (1/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (34.0ms) Inference, (3.9ms) NMS\n",
            "video 1/1 (2/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (34.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (3/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (34.1ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (4/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (28.4ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (5/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (28.3ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (6/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (27.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (7/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.7ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (8/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.3ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (9/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.4ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (10/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.4ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (11/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (12/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (13/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (14/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.4ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (15/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (27.1ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (16/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (17/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (18/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (19/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (20/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (26.3ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (21/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (26.2ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (22/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (23/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (26.7ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (24/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (26.3ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (25/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (26.1ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (26/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (26.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (27/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (26.3ms) Inference, (1.7ms) NMS\n",
            "video 1/1 (28/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (28.4ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (29/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (30.2ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (30/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (26.0ms) Inference, (2.6ms) NMS\n",
            "video 1/1 (31/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (27.9ms) Inference, (2.0ms) NMS\n",
            "video 1/1 (32/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (38.3ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (33/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (27.1ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (34/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (27.0ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (35/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (26.2ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (36/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (40.0ms) Inference, (4.4ms) NMS\n",
            "video 1/1 (37/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (25.9ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (38/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (26.2ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (39/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (32.8ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (40/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (37.8ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (41/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (30.5ms) Inference, (1.7ms) NMS\n",
            "video 1/1 (42/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (26.1ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (43/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (26.1ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (44/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (37.7ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (45/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (26.1ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (46/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (26.0ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (47/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (26.1ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (48/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (27.0ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (49/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (26.5ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (50/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.3ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (51/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.0ms) Inference, (1.8ms) NMS\n",
            "video 1/1 (52/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (38.7ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (53/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (33.8ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (54/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (28.2ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (55/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (27.0ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (56/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (38.3ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (57/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (27.0ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (58/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (36.6ms) Inference, (3.4ms) NMS\n",
            "video 1/1 (59/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (42.1ms) Inference, (1.9ms) NMS\n",
            "video 1/1 (60/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (56.8ms) Inference, (4.0ms) NMS\n",
            "video 1/1 (61/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (38.0ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (62/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (52.2ms) Inference, (3.3ms) NMS\n",
            "video 1/1 (63/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (46.3ms) Inference, (2.9ms) NMS\n",
            "video 1/1 (64/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (36.2ms) Inference, (3.7ms) NMS\n",
            "video 1/1 (65/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (40.8ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (66/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (54.8ms) Inference, (5.8ms) NMS\n",
            "video 1/1 (67/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (60.6ms) Inference, (3.4ms) NMS\n",
            "video 1/1 (68/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (59.9ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (69/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (33.1ms) Inference, (3.2ms) NMS\n",
            "video 1/1 (70/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (48.5ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (71/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (56.8ms) Inference, (4.4ms) NMS\n",
            "video 1/1 (72/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (64.1ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (73/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (34.4ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (74/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (37.6ms) Inference, (4.6ms) NMS\n",
            "video 1/1 (75/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 4 vehicles, Done. (31.9ms) Inference, (1.7ms) NMS\n",
            "video 1/1 (76/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 4 vehicles, Done. (44.7ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (77/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 4 vehicles, Done. (33.0ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (78/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (31.9ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (79/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (31.7ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (80/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (29.2ms) Inference, (1.9ms) NMS\n",
            "video 1/1 (81/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (28.8ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (82/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (28.8ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (83/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (28.9ms) Inference, (1.7ms) NMS\n",
            "video 1/1 (84/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (31.9ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (85/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (29.9ms) Inference, (2.1ms) NMS\n",
            "video 1/1 (86/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (32.7ms) Inference, (3.6ms) NMS\n",
            "video 1/1 (87/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (28.8ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (88/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (58.2ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (89/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (35.0ms) Inference, (2.1ms) NMS\n",
            "video 1/1 (90/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (28.8ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (91/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (28.9ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (92/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (29.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (93/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (28.8ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (94/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (28.7ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (95/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (28.8ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (96/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (28.8ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (97/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.7ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (98/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.6ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (99/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (100/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.7ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (101/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.7ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (102/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.5ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (103/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.5ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (104/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.6ms) Inference, (1.7ms) NMS\n",
            "video 1/1 (105/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.1ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (106/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.2ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (107/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (108/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.7ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (109/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (110/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (111/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (112/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (113/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.3ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (114/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.6ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (115/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.4ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (116/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.2ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (117/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (118/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.4ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (119/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.3ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (120/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (121/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.3ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (122/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.2ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (123/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.2ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (124/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.3ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (125/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (126/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (127/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (128/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (129/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (130/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (131/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 12 vehicles, Done. (26.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (132/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.5ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (133/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (134/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (135/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.3ms) Inference, (2.6ms) NMS\n",
            "video 1/1 (136/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (137/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (138/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (26.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (139/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.2ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (140/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (141/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.5ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (142/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (143/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.4ms) Inference, (2.0ms) NMS\n",
            "video 1/1 (144/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (26.1ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (145/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (146/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (147/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.7ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (148/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.2ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (149/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.3ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (150/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (26.4ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (151/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (26.3ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (152/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (26.3ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (153/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (26.4ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (154/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (26.7ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (155/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (26.1ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (156/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (26.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (157/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (158/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (26.3ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (159/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (26.2ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (160/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 5 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (161/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 6 vehicles, Done. (26.7ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (162/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (27.1ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (163/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (164/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (165/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.3ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (166/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (26.7ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (167/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (168/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.2ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (169/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (170/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (171/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.3ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (172/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.2ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (173/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.1ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (174/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (175/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (176/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (177/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.1ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (178/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (27.7ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (179/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (180/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (181/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (182/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.4ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (183/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.3ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (184/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (185/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.4ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (186/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.5ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (187/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.2ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (188/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.3ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (189/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.3ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (190/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (191/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (192/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.4ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (193/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.2ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (194/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.1ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (195/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (196/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (197/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (198/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.3ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (199/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.7ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (200/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (201/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (27.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (202/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (203/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (204/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (205/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 12 vehicles, Done. (26.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (206/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (207/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.6ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (208/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (209/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.3ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (210/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.3ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (211/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (27.0ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (212/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (213/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.2ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (214/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.8ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (215/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (216/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (217/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (218/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (219/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.3ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (220/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.3ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (221/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (222/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.5ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (223/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (224/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.3ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (225/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (226/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.4ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (227/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (228/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (229/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.2ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (230/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (231/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (29.4ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (232/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (233/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (234/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (235/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.2ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (236/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.2ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (237/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.7ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (238/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (239/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 12 vehicles, Done. (26.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (240/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 12 vehicles, Done. (26.5ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (241/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.2ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (242/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (243/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (244/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 12 vehicles, Done. (26.4ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (245/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.2ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (246/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (247/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (248/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.4ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (249/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (33.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (250/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.1ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (251/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.3ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (252/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (253/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.8ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (254/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.5ms) Inference, (1.7ms) NMS\n",
            "video 1/1 (255/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.3ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (256/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.2ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (257/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.2ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (258/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.7ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (259/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (260/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (261/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (26.5ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (262/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (26.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (263/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.3ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (264/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (265/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 13 vehicles, Done. (26.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (266/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 12 vehicles, Done. (26.4ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (267/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (28.2ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (268/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (28.2ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (269/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (28.8ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (270/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (29.2ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (271/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (33.3ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (272/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.1ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (273/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.1ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (274/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 12 vehicles, Done. (38.5ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (275/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 12 vehicles, Done. (26.3ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (276/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 12 vehicles, Done. (26.0ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (277/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.1ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (278/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 12 vehicles, Done. (33.7ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (279/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (44.3ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (280/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.2ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (281/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.0ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (282/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.1ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (283/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (28.2ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (284/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (26.1ms) Inference, (37.1ms) NMS\n",
            "video 1/1 (285/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (29.1ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (286/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (26.0ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (287/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (27.8ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (288/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (32.4ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (289/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (27.9ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (290/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (27.9ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (291/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 11 vehicles, Done. (27.2ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (292/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (28.2ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (293/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (27.2ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (294/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (38.8ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (295/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (29.9ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (296/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (27.3ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (297/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (27.2ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (298/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (27.1ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (299/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (27.2ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (300/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (27.1ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (301/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (27.0ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (302/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (27.1ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (303/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (35.8ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (304/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (27.0ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (305/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (27.2ms) Inference, (1.7ms) NMS\n",
            "video 1/1 (306/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (29.0ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (307/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (30.6ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (308/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (27.2ms) Inference, (1.7ms) NMS\n",
            "video 1/1 (309/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (27.3ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (310/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (30.4ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (311/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (43.6ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (312/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (29.6ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (313/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (28.2ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (314/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (29.2ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (315/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (30.2ms) Inference, (1.8ms) NMS\n",
            "video 1/1 (316/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (31.6ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (317/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (28.4ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (318/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (27.4ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (319/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (34.9ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (320/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 9 vehicles, Done. (32.4ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (321/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 10 vehicles, Done. (30.3ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (322/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (27.4ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (323/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (26.9ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (324/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (38.0ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (325/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (26.9ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (326/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (27.0ms) Inference, (1.7ms) NMS\n",
            "video 1/1 (327/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (27.4ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (328/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (26.8ms) Inference, (3.5ms) NMS\n",
            "video 1/1 (329/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (27.4ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (330/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (27.7ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (331/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (31.0ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (332/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (27.7ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (333/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (28.3ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (334/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 8 vehicles, Done. (32.8ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (335/335) /content/drive/MyDrive/yolov7/traffic-27260.mp4: 7 vehicles, Done. (28.6ms) Inference, (1.8ms) NMS\n",
            "Done. (22.883s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UKpoup0eunU4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}